# whun
Humor generation project based on tuning GPT-2 on jokes corpora

* folder “first run” contains the first three experiments (on little data);
* folder “data” contains preprocessing scripts, as well as all datasets with different preprocessing;
* “model_X” folders contain models for the corresponding runs;
* generate.py is for joke generation given a model;
* run_clm.py is the script for generative models training;
* runs.txt contains info on how the training was run for all the models
