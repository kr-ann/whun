# whun
Humor generation project based on tuning GPT-2 on jokes corpora

**Preprocessing**
* Data preprocessing.ipynb is the notebook with data visualization and preprocessing;
* preprocess_before_train.py is the script for the final data cleaning before the training.

**Model training**
* run_clm.py is the script for generative models training;
* runs.txt contains info on how the training was run for all the models;
* generate.py is the script for joke generation given a model.

Humor generation report.pdf contains description of experiments and a brief analysis of results.
