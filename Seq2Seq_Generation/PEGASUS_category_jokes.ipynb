{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PEGASUS_category_jokes.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPs6a5R3A2Cl"
      },
      "source": [
        "!pip install transformers\n",
        "!pip3 install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vcfeB4oTec_"
      },
      "source": [
        "import datetime\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split, RandomSampler, SequentialSampler\n",
        "torch.manual_seed(42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2Wc0WHOBZ2O"
      },
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlK2infy7uCC"
      },
      "source": [
        "# Load model checkpoint from huggingface Library\n",
        "\n",
        "Load the model which you want to use and load the tokenizer for that model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jDDGcVdTpP0"
      },
      "source": [
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model_name = 'google/pegasus-xsum'\n",
        "tokenizer = PegasusTokenizer.from_pretrained(model_name)\n",
        "model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcpC4COv7pdb"
      },
      "source": [
        "# Download and Prepare Data\n",
        "\n",
        "Download the data from github repo. Load the dataset from the .json file and remove the unwanted columns. Divide the dataset for training and validation. Use the categories in validation data to generate jokes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VplF9g3HT3iY"
      },
      "source": [
        "!git clone https://github.com/taivop/joke-dataset.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Esl4nGNNWVn2"
      },
      "source": [
        "y = pd.read_json('joke-dataset/wocka.json')\n",
        "del y['id']\n",
        "del y['title'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRe6m4c5T4ZB"
      },
      "source": [
        "z = pd.read_json('joke-dataset/stupidstuff.json')\n",
        "del z['id']\n",
        "del z['rating'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjU7jzEKCaYg"
      },
      "source": [
        "sum_data = pd.concat([y,z])\n",
        "sum_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6wdeci-T6tD"
      },
      "source": [
        "sum_data = sum_data.sample(len(sum_data), random_state=20)\n",
        "train_sub = int(len(sum_data) * 0.99)\n",
        "\n",
        "train_df = sum_data[0:train_sub]\n",
        "val_df = sum_data[train_sub:]\n",
        "\n",
        "train_texts = list(train_df['category'])\n",
        "val_texts = list(val_df['category'])\n",
        "\n",
        "train_decode = list(train_df['body'])\n",
        "val_decode = list(val_df['body'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6IA3N-a__Q7W"
      },
      "source": [
        "# Tokenize\n",
        "\n",
        "Tokenize the data and convert them to a pytorch data object for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OagFc2yUOg7"
      },
      "source": [
        "train_encodings = tokenizer(train_texts, max_length=16, truncation=True, padding='longest')\n",
        "val_encodings = tokenizer(val_texts, max_length=16, truncation=True, padding='longest')\n",
        "\n",
        "train_labels = tokenizer(train_decode, max_length=512, truncation=True, padding='longest')\n",
        "val_labels = tokenizer(val_decode, max_length=512, truncation=True, padding='longest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3W6M9kpUSXl"
      },
      "source": [
        "class Summary_dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels['input_ids'][idx])  # torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5E5g8SeUUGr"
      },
      "source": [
        "train_dataset = Summary_dataset(train_encodings, train_labels)\n",
        "val_dataset = Summary_dataset(val_encodings, val_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FML_o5eL7kB1"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a3nh5fjUUiU"
      },
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=100,              # total number of training epochs\n",
        "    per_device_train_batch_size=64,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=5,\n",
        "    eval_accumulation_steps=1,\n",
        "    learning_rate=1e-4,\n",
        "    adafactor = True                #use adafactor instead of adam\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUZPFCX0UV36"
      },
      "source": [
        "trainer = Trainer(\n",
        "    model=model,                         # the instantiated Transformers model to be trained\n",
        "    args=training_args,                  # training arguments, defined above\n",
        "    train_dataset=train_dataset,         # training dataset\n",
        "    eval_dataset=val_dataset             # evaluation dataset\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvoFDCOsUYC-"
      },
      "source": [
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r0GurVX7eS5"
      },
      "source": [
        "# Generate Text\n",
        "\n",
        "Generate text using different sets of arguments. You can find more on generating text here: [How to generate text: using different decoding methods for language generation with Transformers](https://huggingface.co/blog/how-to-generate)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0e_foQ7dJHH"
      },
      "source": [
        "batch = tokenizer('Medical', truncation=True, padding='longest', return_tensors=\"pt\").to(torch_device)\n",
        "generated = model.generate(**batch, min_length=32, do_sample=True, top_p=0.92, top_k=0, num_beams=8, no_repeat_ngram_size=2)\n",
        "tgt_text = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
        "tgt_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbMjvB158D67"
      },
      "source": [
        "# Save Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHcazk-RVpI5"
      },
      "source": [
        "trainer.save_model('pegasus_jokes_2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVBu_8mK8J3J"
      },
      "source": [
        "# Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84X8Jnpr8paP"
      },
      "source": [
        "from transformers import PegasusConfig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6oGwhzix8I1L"
      },
      "source": [
        "torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "tokenizer = PegasusTokenizer.from_pretrained('google/pegasus-xsum')\n",
        "config = PegasusConfig.from_json_file('./content/saved_model/*.config') #Path of .config file\n",
        "model = PegasusForConditionalGeneration.from_pretrained('./content/saved_model/pytorch_model.bin', config=config).to(torch_device) #path of .bin file"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}